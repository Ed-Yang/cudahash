//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29618528
// Cuda compilation tools, release 11.2, V11.2.152
// Based on NVVM 7.0.1
//

.version 7.2
.target sm_61
.address_size 64

.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.global .align 1 .b8 $str[30] = {37, 48, 50, 100, 32, 37, 117, 58, 37, 117, 32, 37, 117, 58, 37, 117, 32, 37, 117, 58, 37, 117, 32, 37, 117, 58, 37, 117, 10, 0};
.global .align 1 .b8 $str$1[47] = {37, 48, 50, 100, 32, 109, 97, 115, 107, 32, 61, 32, 48, 120, 37, 120, 32, 118, 97, 108, 117, 101, 32, 61, 32, 48, 120, 37, 120, 32, 40, 97, 99, 116, 105, 118, 101, 32, 61, 32, 48, 120, 37, 120, 41, 10, 0};

.entry _Z11test_sync_1v()
{
	.local .align 8 .b8 	__local_depot0[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<73>;
	.reg .b32 	%r<419>;
	.reg .b64 	%rd<5>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	mov.u32 	%r1, %tid.x;
	and.b32  	%r2, %r1, 7;
	mov.u32 	%r205, 7;
	mul.lo.s32 	%r3, %r1, 10;
	mov.u32 	%r206, 6175;
	mov.u32 	%r204, 0;
	mov.u32 	%r207, -1;
	shfl.sync.idx.b32 	%r4|%p1, %r3, %r204, %r206, %r207;
	mov.u32 	%r208, 1;
	shfl.sync.idx.b32 	%r5|%p2, %r3, %r208, %r206, %r207;
	mov.u32 	%r209, 2;
	shfl.sync.idx.b32 	%r6|%p3, %r3, %r209, %r206, %r207;
	mov.u32 	%r210, 3;
	shfl.sync.idx.b32 	%r7|%p4, %r3, %r210, %r206, %r207;
	mov.u32 	%r211, 4;
	shfl.sync.idx.b32 	%r8|%p5, %r3, %r211, %r206, %r207;
	mov.u32 	%r212, 5;
	shfl.sync.idx.b32 	%r9|%p6, %r3, %r212, %r206, %r207;
	mov.u32 	%r213, 6;
	shfl.sync.idx.b32 	%r10|%p7, %r3, %r213, %r206, %r207;
	shfl.sync.idx.b32 	%r11|%p8, %r3, %r205, %r206, %r207;
	setp.ne.s32 	%p65, %r2, 0;
	mov.u32 	%r363, %r204;
	mov.u32 	%r364, %r204;
	mov.u32 	%r365, %r204;
	mov.u32 	%r366, %r204;
	mov.u32 	%r367, %r204;
	mov.u32 	%r368, %r204;
	mov.u32 	%r369, %r204;
	mov.u32 	%r370, %r204;
	@%p65 bra 	LBB0_2;

	mov.u32 	%r363, %r4;
	mov.u32 	%r364, %r5;
	mov.u32 	%r365, %r6;
	mov.u32 	%r366, %r7;
	mov.u32 	%r367, %r8;
	mov.u32 	%r368, %r9;
	mov.u32 	%r369, %r10;
	mov.u32 	%r370, %r11;

LBB0_2:
	mov.u32 	%r299, 7;
	mov.u32 	%r298, 6;
	mov.u32 	%r297, 5;
	mov.u32 	%r296, 4;
	mov.u32 	%r295, 3;
	mov.u32 	%r294, 2;
	mov.u32 	%r293, 1;
	mov.u32 	%r292, 6175;
	mov.u32 	%r291, -1;
	add.s32 	%r214, %r3, 1;
	shfl.sync.idx.b32 	%r28|%p9, %r214, %r204, %r292, %r291;
	shfl.sync.idx.b32 	%r29|%p10, %r214, %r293, %r292, %r291;
	shfl.sync.idx.b32 	%r30|%p11, %r214, %r294, %r292, %r291;
	shfl.sync.idx.b32 	%r31|%p12, %r214, %r295, %r292, %r291;
	shfl.sync.idx.b32 	%r32|%p13, %r214, %r296, %r292, %r291;
	shfl.sync.idx.b32 	%r33|%p14, %r214, %r297, %r292, %r291;
	shfl.sync.idx.b32 	%r34|%p15, %r214, %r298, %r292, %r291;
	shfl.sync.idx.b32 	%r35|%p16, %r214, %r299, %r292, %r291;
	setp.ne.s32 	%p66, %r2, 1;
	@%p66 bra 	LBB0_4;

	mov.u32 	%r363, %r28;
	mov.u32 	%r364, %r29;
	mov.u32 	%r365, %r30;
	mov.u32 	%r366, %r31;
	mov.u32 	%r367, %r32;
	mov.u32 	%r368, %r33;
	mov.u32 	%r369, %r34;
	mov.u32 	%r370, %r35;

LBB0_4:
	mov.u32 	%r308, 7;
	mov.u32 	%r307, 6;
	mov.u32 	%r306, 5;
	mov.u32 	%r305, 4;
	mov.u32 	%r304, 3;
	mov.u32 	%r303, 2;
	mov.u32 	%r302, 1;
	mov.u32 	%r301, 6175;
	mov.u32 	%r300, -1;
	add.s32 	%r225, %r3, 2;
	mov.u32 	%r228, 0;
	shfl.sync.idx.b32 	%r52|%p17, %r225, %r228, %r301, %r300;
	shfl.sync.idx.b32 	%r53|%p18, %r225, %r302, %r301, %r300;
	shfl.sync.idx.b32 	%r54|%p19, %r225, %r303, %r301, %r300;
	shfl.sync.idx.b32 	%r55|%p20, %r225, %r304, %r301, %r300;
	shfl.sync.idx.b32 	%r56|%p21, %r225, %r305, %r301, %r300;
	shfl.sync.idx.b32 	%r57|%p22, %r225, %r306, %r301, %r300;
	shfl.sync.idx.b32 	%r58|%p23, %r225, %r307, %r301, %r300;
	shfl.sync.idx.b32 	%r59|%p24, %r225, %r308, %r301, %r300;
	setp.ne.s32 	%p67, %r2, 2;
	@%p67 bra 	LBB0_6;

	mov.u32 	%r363, %r52;
	mov.u32 	%r364, %r53;
	mov.u32 	%r365, %r54;
	mov.u32 	%r366, %r55;
	mov.u32 	%r367, %r56;
	mov.u32 	%r368, %r57;
	mov.u32 	%r369, %r58;
	mov.u32 	%r370, %r59;

LBB0_6:
	mov.u32 	%r317, 7;
	mov.u32 	%r316, 6;
	mov.u32 	%r315, 5;
	mov.u32 	%r314, 4;
	mov.u32 	%r313, 3;
	mov.u32 	%r312, 2;
	mov.u32 	%r311, 1;
	mov.u32 	%r310, 6175;
	mov.u32 	%r309, -1;
	add.s32 	%r236, %r3, 3;
	shfl.sync.idx.b32 	%r76|%p25, %r236, %r228, %r310, %r309;
	shfl.sync.idx.b32 	%r77|%p26, %r236, %r311, %r310, %r309;
	shfl.sync.idx.b32 	%r78|%p27, %r236, %r312, %r310, %r309;
	shfl.sync.idx.b32 	%r79|%p28, %r236, %r313, %r310, %r309;
	shfl.sync.idx.b32 	%r80|%p29, %r236, %r314, %r310, %r309;
	shfl.sync.idx.b32 	%r81|%p30, %r236, %r315, %r310, %r309;
	shfl.sync.idx.b32 	%r82|%p31, %r236, %r316, %r310, %r309;
	shfl.sync.idx.b32 	%r83|%p32, %r236, %r317, %r310, %r309;
	setp.ne.s32 	%p68, %r2, 3;
	@%p68 bra 	LBB0_8;

	mov.u32 	%r363, %r76;
	mov.u32 	%r364, %r77;
	mov.u32 	%r365, %r78;
	mov.u32 	%r366, %r79;
	mov.u32 	%r367, %r80;
	mov.u32 	%r368, %r81;
	mov.u32 	%r369, %r82;
	mov.u32 	%r370, %r83;

LBB0_8:
	mov.u32 	%r326, 7;
	mov.u32 	%r325, 6;
	mov.u32 	%r324, 5;
	mov.u32 	%r323, 4;
	mov.u32 	%r322, 3;
	mov.u32 	%r321, 2;
	mov.u32 	%r320, 1;
	mov.u32 	%r319, 6175;
	mov.u32 	%r318, -1;
	add.s32 	%r100, %r3, 401;
	add.s32 	%r247, %r3, 400;
	shfl.sync.idx.b32 	%r101|%p33, %r247, %r228, %r319, %r318;
	shfl.sync.idx.b32 	%r102|%p34, %r247, %r320, %r319, %r318;
	shfl.sync.idx.b32 	%r103|%p35, %r247, %r321, %r319, %r318;
	shfl.sync.idx.b32 	%r104|%p36, %r247, %r322, %r319, %r318;
	shfl.sync.idx.b32 	%r105|%p37, %r247, %r323, %r319, %r318;
	shfl.sync.idx.b32 	%r106|%p38, %r247, %r324, %r319, %r318;
	shfl.sync.idx.b32 	%r107|%p39, %r247, %r325, %r319, %r318;
	shfl.sync.idx.b32 	%r108|%p40, %r247, %r326, %r319, %r318;
	setp.ne.s32 	%p69, %r2, 4;
	@%p69 bra 	LBB0_10;

	mov.u32 	%r363, %r101;
	mov.u32 	%r364, %r102;
	mov.u32 	%r365, %r103;
	mov.u32 	%r366, %r104;
	mov.u32 	%r367, %r105;
	mov.u32 	%r368, %r106;
	mov.u32 	%r369, %r107;
	mov.u32 	%r370, %r108;

LBB0_10:
	mov.u32 	%r335, 7;
	mov.u32 	%r334, 6;
	mov.u32 	%r333, 5;
	mov.u32 	%r332, 4;
	mov.u32 	%r331, 3;
	mov.u32 	%r330, 2;
	mov.u32 	%r329, 1;
	mov.u32 	%r328, 6175;
	mov.u32 	%r327, -1;
	shfl.sync.idx.b32 	%r125|%p41, %r100, %r228, %r328, %r327;
	shfl.sync.idx.b32 	%r126|%p42, %r100, %r329, %r328, %r327;
	shfl.sync.idx.b32 	%r127|%p43, %r100, %r330, %r328, %r327;
	shfl.sync.idx.b32 	%r128|%p44, %r100, %r331, %r328, %r327;
	shfl.sync.idx.b32 	%r129|%p45, %r100, %r332, %r328, %r327;
	shfl.sync.idx.b32 	%r130|%p46, %r100, %r333, %r328, %r327;
	shfl.sync.idx.b32 	%r131|%p47, %r100, %r334, %r328, %r327;
	shfl.sync.idx.b32 	%r132|%p48, %r100, %r335, %r328, %r327;
	setp.ne.s32 	%p70, %r2, 5;
	@%p70 bra 	LBB0_12;

	mov.u32 	%r363, %r125;
	mov.u32 	%r364, %r126;
	mov.u32 	%r365, %r127;
	mov.u32 	%r366, %r128;
	mov.u32 	%r367, %r129;
	mov.u32 	%r368, %r130;
	mov.u32 	%r369, %r131;
	mov.u32 	%r370, %r132;

LBB0_12:
	mov.u32 	%r344, 7;
	mov.u32 	%r343, 6;
	mov.u32 	%r342, 5;
	mov.u32 	%r341, 4;
	mov.u32 	%r340, 3;
	mov.u32 	%r339, 2;
	mov.u32 	%r338, 1;
	mov.u32 	%r337, 6175;
	mov.u32 	%r336, -1;
	add.s32 	%r268, %r100, 1;
	shfl.sync.idx.b32 	%r149|%p49, %r268, %r228, %r337, %r336;
	shfl.sync.idx.b32 	%r150|%p50, %r268, %r338, %r337, %r336;
	shfl.sync.idx.b32 	%r151|%p51, %r268, %r339, %r337, %r336;
	shfl.sync.idx.b32 	%r152|%p52, %r268, %r340, %r337, %r336;
	shfl.sync.idx.b32 	%r153|%p53, %r268, %r341, %r337, %r336;
	shfl.sync.idx.b32 	%r154|%p54, %r268, %r342, %r337, %r336;
	shfl.sync.idx.b32 	%r155|%p55, %r268, %r343, %r337, %r336;
	shfl.sync.idx.b32 	%r156|%p56, %r268, %r344, %r337, %r336;
	setp.ne.s32 	%p71, %r2, 6;
	@%p71 bra 	LBB0_14;

	mov.u32 	%r363, %r149;
	mov.u32 	%r364, %r150;
	mov.u32 	%r365, %r151;
	mov.u32 	%r366, %r152;
	mov.u32 	%r367, %r153;
	mov.u32 	%r368, %r154;
	mov.u32 	%r369, %r155;
	mov.u32 	%r370, %r156;

LBB0_14:
	mov.u32 	%r353, 7;
	mov.u32 	%r352, 6;
	mov.u32 	%r351, 5;
	mov.u32 	%r350, 4;
	mov.u32 	%r349, 3;
	mov.u32 	%r348, 2;
	mov.u32 	%r347, 1;
	mov.u32 	%r346, 6175;
	mov.u32 	%r345, -1;
	add.s32 	%r279, %r100, 2;
	shfl.sync.idx.b32 	%r173|%p57, %r279, %r228, %r346, %r345;
	shfl.sync.idx.b32 	%r174|%p58, %r279, %r347, %r346, %r345;
	shfl.sync.idx.b32 	%r175|%p59, %r279, %r348, %r346, %r345;
	shfl.sync.idx.b32 	%r176|%p60, %r279, %r349, %r346, %r345;
	shfl.sync.idx.b32 	%r177|%p61, %r279, %r350, %r346, %r345;
	shfl.sync.idx.b32 	%r178|%p62, %r279, %r351, %r346, %r345;
	shfl.sync.idx.b32 	%r179|%p63, %r279, %r352, %r346, %r345;
	shfl.sync.idx.b32 	%r180|%p64, %r279, %r353, %r346, %r345;
	setp.ne.s32 	%p72, %r2, 7;
	@%p72 bra 	LBB0_16;

	mov.u32 	%r363, %r173;
	mov.u32 	%r364, %r174;
	mov.u32 	%r365, %r175;
	mov.u32 	%r366, %r176;
	mov.u32 	%r367, %r177;
	mov.u32 	%r368, %r178;
	mov.u32 	%r369, %r179;
	mov.u32 	%r370, %r180;

LBB0_16:
	mov.u32 	%r354, %tid.x;
	add.u64 	%rd1, %SP, 0;
	add.u64 	%rd2, %SPL, 0;
	st.local.v2.u32 	[%rd2], {%r354, %r363};
	st.local.v2.u32 	[%rd2+8], {%r364, %r365};
	st.local.v2.u32 	[%rd2+16], {%r366, %r367};
	st.local.v2.u32 	[%rd2+24], {%r368, %r369};
	st.local.u32 	[%rd2+32], %r370;
	mov.u64 	%rd3, $str;
	cvta.global.u64 	%rd4, %rd3;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r290, [retval0+0];
	} // callseq 0
	ret;

}
.entry _Z11test_sync_2v()
{
	.local .align 16 .b8 	__local_depot1[176];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<73>;
	.reg .b16 	%rs<9>;
	.reg .b32 	%r<110>;
	.reg .b64 	%rd<37>;


	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	add.u64 	%rd1, %SP, 0;
	add.u64 	%rd2, %SPL, 0;
	mov.u32 	%r1, 0;
	st.local.v4.u32 	[%rd2], {%r1, %r1, %r1, %r1};
	add.s64 	%rd3, %rd1, 16;
	cvta.to.local.u64 	%rd4, %rd3;
	st.local.v4.u32 	[%rd4], {%r1, %r1, %r1, %r1};
	add.s64 	%rd5, %rd1, 32;
	cvta.to.local.u64 	%rd6, %rd5;
	st.local.v4.u32 	[%rd6], {%r1, %r1, %r1, %r1};
	add.s64 	%rd7, %rd1, 48;
	cvta.to.local.u64 	%rd8, %rd7;
	st.local.v4.u32 	[%rd8], {%r1, %r1, %r1, %r1};
	add.s64 	%rd9, %rd1, 64;
	cvta.to.local.u64 	%rd10, %rd9;
	st.local.v4.u32 	[%rd10], {%r1, %r1, %r1, %r1};
	add.s64 	%rd11, %rd1, 80;
	cvta.to.local.u64 	%rd12, %rd11;
	st.local.v4.u32 	[%rd12], {%r1, %r1, %r1, %r1};
	add.s64 	%rd13, %rd1, 96;
	cvta.to.local.u64 	%rd14, %rd13;
	st.local.v4.u32 	[%rd14], {%r1, %r1, %r1, %r1};
	add.s64 	%rd15, %rd1, 112;
	cvta.to.local.u64 	%rd16, %rd15;
	st.local.v4.u32 	[%rd16], {%r1, %r1, %r1, %r1};
	mov.u32 	%r2, %tid.x;
	and.b32  	%r3, %r2, 7;
	mov.u32 	%r4, 7;
	mul.lo.s32 	%r5, %r2, 10;
	or.b32  	%r6, %r5, 1;
	mov.u32 	%r7, 1;
	add.s32 	%r8, %r5, 2;
	mov.u32 	%r9, 2;
	add.s32 	%r10, %r5, 3;
	mov.u32 	%r11, 3;
	mov.u32 	%r12, 6175;
	mov.u32 	%r13, -1;
	mov.u32 	%r14, 4;
	mov.u32 	%r15, 5;
	mov.u32 	%r16, 6;
	setp.ne.s32 	%p1, %r3, 0;
	selp.u16 	%rs1, 1, 0, %p1;
	mul.wide.u16 	%r17, %rs1, 4;
	mul.wide.u32 	%rd17, %r17, 8;
	add.s64 	%rd18, %rd2, %rd17;
	shfl.sync.idx.b32 	%r18|%p2, %r5, %r1, %r12, %r13;
	shfl.sync.idx.b32 	%r19|%p3, %r5, %r7, %r12, %r13;
	shfl.sync.idx.b32 	%r20|%p4, %r5, %r9, %r12, %r13;
	shfl.sync.idx.b32 	%r21|%p5, %r5, %r11, %r12, %r13;
	shfl.sync.idx.b32 	%r22|%p6, %r5, %r14, %r12, %r13;
	shfl.sync.idx.b32 	%r23|%p7, %r5, %r15, %r12, %r13;
	shfl.sync.idx.b32 	%r24|%p8, %r5, %r16, %r12, %r13;
	shfl.sync.idx.b32 	%r25|%p9, %r5, %r4, %r12, %r13;
	st.local.v4.u32 	[%rd18+64], {%r18, %r19, %r20, %r21};
	st.local.v4.u32 	[%rd18+80], {%r22, %r23, %r24, %r25};
	setp.ne.s32 	%p10, %r3, 1;
	selp.u16 	%rs2, 1, 0, %p10;
	mul.wide.u16 	%r26, %rs2, 4;
	mul.wide.u32 	%rd19, %r26, 8;
	add.s64 	%rd20, %rd2, %rd19;
	shfl.sync.idx.b32 	%r27|%p11, %r6, %r1, %r12, %r13;
	shfl.sync.idx.b32 	%r28|%p12, %r6, %r7, %r12, %r13;
	shfl.sync.idx.b32 	%r29|%p13, %r6, %r9, %r12, %r13;
	shfl.sync.idx.b32 	%r30|%p14, %r6, %r11, %r12, %r13;
	shfl.sync.idx.b32 	%r31|%p15, %r6, %r14, %r12, %r13;
	shfl.sync.idx.b32 	%r32|%p16, %r6, %r15, %r12, %r13;
	shfl.sync.idx.b32 	%r33|%p17, %r6, %r16, %r12, %r13;
	shfl.sync.idx.b32 	%r34|%p18, %r6, %r4, %r12, %r13;
	st.local.v4.u32 	[%rd20+64], {%r27, %r28, %r29, %r30};
	st.local.v4.u32 	[%rd20+80], {%r31, %r32, %r33, %r34};
	setp.ne.s32 	%p19, %r3, 2;
	selp.u16 	%rs3, 1, 0, %p19;
	mul.wide.u16 	%r35, %rs3, 4;
	mul.wide.u32 	%rd21, %r35, 8;
	add.s64 	%rd22, %rd2, %rd21;
	shfl.sync.idx.b32 	%r36|%p20, %r8, %r1, %r12, %r13;
	shfl.sync.idx.b32 	%r37|%p21, %r8, %r7, %r12, %r13;
	shfl.sync.idx.b32 	%r38|%p22, %r8, %r9, %r12, %r13;
	shfl.sync.idx.b32 	%r39|%p23, %r8, %r11, %r12, %r13;
	shfl.sync.idx.b32 	%r40|%p24, %r8, %r14, %r12, %r13;
	shfl.sync.idx.b32 	%r41|%p25, %r8, %r15, %r12, %r13;
	shfl.sync.idx.b32 	%r42|%p26, %r8, %r16, %r12, %r13;
	shfl.sync.idx.b32 	%r43|%p27, %r8, %r4, %r12, %r13;
	st.local.v4.u32 	[%rd22+64], {%r36, %r37, %r38, %r39};
	st.local.v4.u32 	[%rd22+80], {%r40, %r41, %r42, %r43};
	setp.ne.s32 	%p28, %r3, 3;
	selp.u16 	%rs4, 1, 0, %p28;
	mul.wide.u16 	%r44, %rs4, 4;
	mul.wide.u32 	%rd23, %r44, 8;
	add.s64 	%rd24, %rd2, %rd23;
	shfl.sync.idx.b32 	%r45|%p29, %r10, %r1, %r12, %r13;
	shfl.sync.idx.b32 	%r46|%p30, %r10, %r7, %r12, %r13;
	shfl.sync.idx.b32 	%r47|%p31, %r10, %r9, %r12, %r13;
	shfl.sync.idx.b32 	%r48|%p32, %r10, %r11, %r12, %r13;
	shfl.sync.idx.b32 	%r49|%p33, %r10, %r14, %r12, %r13;
	shfl.sync.idx.b32 	%r50|%p34, %r10, %r15, %r12, %r13;
	shfl.sync.idx.b32 	%r51|%p35, %r10, %r16, %r12, %r13;
	shfl.sync.idx.b32 	%r52|%p36, %r10, %r4, %r12, %r13;
	st.local.v4.u32 	[%rd24+64], {%r45, %r46, %r47, %r48};
	st.local.v4.u32 	[%rd24+80], {%r49, %r50, %r51, %r52};
	add.s32 	%r53, %r5, 400;
	add.s32 	%r54, %r5, 401;
	add.s32 	%r55, %r5, 402;
	add.s32 	%r56, %r5, 403;
	setp.ne.s32 	%p37, %r3, 4;
	selp.u16 	%rs5, 1, 0, %p37;
	mul.wide.u16 	%r57, %rs5, 4;
	mul.wide.u32 	%rd25, %r57, 8;
	add.s64 	%rd26, %rd2, %rd25;
	shfl.sync.idx.b32 	%r58|%p38, %r53, %r1, %r12, %r13;
	shfl.sync.idx.b32 	%r59|%p39, %r53, %r7, %r12, %r13;
	shfl.sync.idx.b32 	%r60|%p40, %r53, %r9, %r12, %r13;
	shfl.sync.idx.b32 	%r61|%p41, %r53, %r11, %r12, %r13;
	shfl.sync.idx.b32 	%r62|%p42, %r53, %r14, %r12, %r13;
	shfl.sync.idx.b32 	%r63|%p43, %r53, %r15, %r12, %r13;
	shfl.sync.idx.b32 	%r64|%p44, %r53, %r16, %r12, %r13;
	shfl.sync.idx.b32 	%r65|%p45, %r53, %r4, %r12, %r13;
	st.local.v4.u32 	[%rd26+64], {%r58, %r59, %r60, %r61};
	st.local.v4.u32 	[%rd26+80], {%r62, %r63, %r64, %r65};
	setp.ne.s32 	%p46, %r3, 5;
	selp.u16 	%rs6, 1, 0, %p46;
	mul.wide.u16 	%r66, %rs6, 4;
	mul.wide.u32 	%rd27, %r66, 8;
	add.s64 	%rd28, %rd2, %rd27;
	shfl.sync.idx.b32 	%r67|%p47, %r54, %r1, %r12, %r13;
	shfl.sync.idx.b32 	%r68|%p48, %r54, %r7, %r12, %r13;
	shfl.sync.idx.b32 	%r69|%p49, %r54, %r9, %r12, %r13;
	shfl.sync.idx.b32 	%r70|%p50, %r54, %r11, %r12, %r13;
	shfl.sync.idx.b32 	%r71|%p51, %r54, %r14, %r12, %r13;
	shfl.sync.idx.b32 	%r72|%p52, %r54, %r15, %r12, %r13;
	shfl.sync.idx.b32 	%r73|%p53, %r54, %r16, %r12, %r13;
	shfl.sync.idx.b32 	%r74|%p54, %r54, %r4, %r12, %r13;
	st.local.v4.u32 	[%rd28+64], {%r67, %r68, %r69, %r70};
	st.local.v4.u32 	[%rd28+80], {%r71, %r72, %r73, %r74};
	setp.ne.s32 	%p55, %r3, 6;
	selp.u16 	%rs7, 1, 0, %p55;
	mul.wide.u16 	%r75, %rs7, 4;
	mul.wide.u32 	%rd29, %r75, 8;
	add.s64 	%rd30, %rd2, %rd29;
	shfl.sync.idx.b32 	%r76|%p56, %r55, %r1, %r12, %r13;
	shfl.sync.idx.b32 	%r77|%p57, %r55, %r7, %r12, %r13;
	shfl.sync.idx.b32 	%r78|%p58, %r55, %r9, %r12, %r13;
	shfl.sync.idx.b32 	%r79|%p59, %r55, %r11, %r12, %r13;
	shfl.sync.idx.b32 	%r80|%p60, %r55, %r14, %r12, %r13;
	shfl.sync.idx.b32 	%r81|%p61, %r55, %r15, %r12, %r13;
	shfl.sync.idx.b32 	%r82|%p62, %r55, %r16, %r12, %r13;
	shfl.sync.idx.b32 	%r83|%p63, %r55, %r4, %r12, %r13;
	st.local.v4.u32 	[%rd30+64], {%r76, %r77, %r78, %r79};
	st.local.v4.u32 	[%rd30+80], {%r80, %r81, %r82, %r83};
	setp.ne.s32 	%p64, %r3, 7;
	selp.u16 	%rs8, 1, 0, %p64;
	mul.wide.u16 	%r84, %rs8, 4;
	mul.wide.u32 	%rd31, %r84, 8;
	add.s64 	%rd32, %rd2, %rd31;
	shfl.sync.idx.b32 	%r85|%p65, %r56, %r1, %r12, %r13;
	shfl.sync.idx.b32 	%r86|%p66, %r56, %r7, %r12, %r13;
	shfl.sync.idx.b32 	%r87|%p67, %r56, %r9, %r12, %r13;
	shfl.sync.idx.b32 	%r88|%p68, %r56, %r11, %r12, %r13;
	shfl.sync.idx.b32 	%r89|%p69, %r56, %r14, %r12, %r13;
	shfl.sync.idx.b32 	%r90|%p70, %r56, %r15, %r12, %r13;
	shfl.sync.idx.b32 	%r91|%p71, %r56, %r16, %r12, %r13;
	shfl.sync.idx.b32 	%r92|%p72, %r56, %r4, %r12, %r13;
	st.local.v4.u32 	[%rd32+64], {%r85, %r86, %r87, %r88};
	st.local.v4.u32 	[%rd32+80], {%r89, %r90, %r91, %r92};
	ld.local.v4.u32 	{%r93, %r94, %r95, %r96}, [%rd2+64];
	ld.local.v4.u32 	{%r98, %r99, %r100, %r101}, [%rd2+80];
	add.u64 	%rd33, %SP, 128;
	add.u64 	%rd34, %SPL, 128;
	st.local.v2.u32 	[%rd34], {%r2, %r93};
	st.local.v2.u32 	[%rd34+8], {%r94, %r95};
	st.local.v2.u32 	[%rd34+16], {%r96, %r98};
	st.local.v2.u32 	[%rd34+24], {%r99, %r100};
	st.local.u32 	[%rd34+32], %r101;
	mov.u64 	%rd35, $str;
	cvta.global.u64 	%rd36, %rd35;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd36;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd33;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r109, [retval0+0];
	} // callseq 1
	ret;

}
.entry _Z11test_sync_3j(
	.param .u32 _Z11test_sync_3j_param_0
)
{
	.local .align 16 .b8 	__local_depot2[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<9>;
	.reg .b64 	%rd<5>;


	mov.u64 	%SPL, __local_depot2;
	cvta.local.u64 	%SP, %SPL;
	mov.u32 	%r2, %tid.x;
	mov.u32 	%r3, 6175;
	mov.u32 	%r4, 0;
	and.b32  	%r5, %r2, 7;
	// begin inline asm
	activemask.b32 %r1;
	// end inline asm
	ld.param.u32 	%r6, [_Z11test_sync_3j_param_0];
	shfl.sync.idx.b32 	%r7|%p1, %r5, %r4, %r3, %r6;
	add.u64 	%rd1, %SP, 0;
	add.u64 	%rd2, %SPL, 0;
	st.local.v4.u32 	[%rd2], {%r5, %r6, %r7, %r1};
	mov.u64 	%rd3, $str$1;
	cvta.global.u64 	%rd4, %rd3;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r8, [retval0+0];
	} // callseq 2
	ret;

}

